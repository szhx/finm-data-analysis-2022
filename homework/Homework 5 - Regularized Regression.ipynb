{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a943587",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "## Data Analysis\n",
    "### FINM August Review \n",
    "\n",
    "Mark Hendricks\n",
    "\n",
    "hendricks@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c989ffe",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "- This homework uses the file, “sp500_returns.xlsx”.\n",
    "- Find the data in the Github repo associated with the module, (link on Canvas.)\n",
    "\n",
    "The data file contains...\n",
    "- Return rates, $r^{GLD}_t$, for the GLD, (an ETF) which tracks the returns on gold.\n",
    "- Return rates, $r^i_t$, for 451 single-name equities$^1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f659a8",
   "metadata": {},
   "source": [
    "## 1. Penalized Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f747a",
   "metadata": {},
   "source": [
    "Consider a regression of GLD, denoted $r^{GLD}$, on all 451 returns of the S&P 500 stocks.\n",
    "$$r^{GLD}_t = \\alpha + \\sum_{j=1}^k\\beta^jr^j_t + \\epsilon_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbfd4b4",
   "metadata": {},
   "source": [
    "1. Estimate (1) with OLS$^2$\n",
    "        \n",
    "    (a) Report the estimated intercept and betas\n",
    "\n",
    "    (b) Report the R-squared\n",
    "\n",
    "    (c) Which factors have the largest betas in explaining $r^{GLD}$?\n",
    "\n",
    "    (d) Calculate $\\beta^j\\sigma^j$ for each regressor$^3$. Which of these is largest in magnitude, and thus most influential in explaining $r^{GLD}$?\n",
    "\n",
    "    (e) Report the matrix condition number$^4$ of $R'R$, where $R$ denotes the matrix of single-name equity return data. Why should this condition number give us pause about trusting the OLS estimates out-of-sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0119dbf",
   "metadata": {},
   "source": [
    "2. Estimate (1) with Ridge Regression. Use a penalty of 0.5 in the estimation$^5$.\n",
    "    \n",
    "    (a) Report the R-squared.\n",
    "    \n",
    "    (b) Based on $\\beta_j\\sigma_j$, which factor is most influential for $r^{GLD}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a5dd4",
   "metadata": {},
   "source": [
    "3. Estimate (1) with LASSO Regression. Use a penalty of 2e-5 in the estimation$^6$.\n",
    "    \n",
    "    (a) Report the estimated intercept and betas.\n",
    "    \n",
    "    (b) Report the R-squared.\n",
    "    \n",
    "    (c) Based on $\\beta_j\\sigma_j$, which factor is most influential for $r^{GLD}$?\n",
    "    \n",
    "    (d) How many regressors have a non-zero beta estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a4d4f",
   "metadata": {},
   "source": [
    "4. How do the estimations compare across the three methods?\n",
    "    \n",
    "    (a) Create a histogram of estimated betas across the three methods, (OLS, Ridge, LASSO.) Are they all nonzero? Are there positive and negative values? Do they range widely in magnitude?\n",
    "    \n",
    "    (b) Which has the largest R-squared? Is this a surprise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb733f",
   "metadata": {},
   "source": [
    "5. Try using cross-validation (with K-folds) to estimate the penalty parameter for Ridge and LASSO. Estimate this CV using two functions from *sklearn.linear_model*\n",
    "    - RidgeCV\n",
    "    - LassoCV\n",
    "\n",
    "   Feel free to use the default parameters, including the default number of folds. Report the CV penalty parameter for Lasso and Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ce5b3",
   "metadata": {},
   "source": [
    "6. Use your estimations based on data through 2020 to fit the model for 2021-2022. \n",
    "\n",
    "    Use the CV penalty parameters (from the previous problem) for Ridge and Lasso. \n",
    "    \n",
    "    What is the r-squared in these out-of-sample fits$^7$? \n",
    "    \n",
    "    Which method does better out-of-sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698321d0",
   "metadata": {},
   "source": [
    "###### Footnotes:\n",
    "<font size=\"3\">\n",
    "    \n",
    "    1. These are all securities in the S&P 500 as of June 2022, filtered for names with sufficient return histories.\n",
    "    2. For this OLS estimation, along with the estimations below, try using scikit-learn in Python      \n",
    "        from sklearn import LinearRegression Lasso Ridge\n",
    "        For OLS, try model_ols = LinearRegression().fit(X,y) \n",
    "    3. The beta being large may simply be because the regressor volatility is small. By scaling by the volatility, we get a better idea of which regressor is driving the most variation.\n",
    "    4. In Python, use \n",
    "        numpy.linalg.cond()\n",
    "    5. Try using \n",
    "        model_ridge = Ridge(alpha=0.5).fit(X,y)\n",
    "    6. Try using \n",
    "        model_lasso = Lasso(alpha=3e-4).fit(X,y)\n",
    "    7. Doing this is really easy in Python. For instance, for the LASSO estimation, you could try\n",
    "        model_lasso = Lasso(alpha=3e-4).fit(X,y)\n",
    "        score_insamp = model_lasso.score(X insamp,y insamp)\n",
    "        score_oos = model_lasso.score(X oos,y oos)   \n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
